---
layout: post
title:  "천재교육 빅데이터 7기 강의 정리 -12"
excerpt: "천재교육 12"

tags:
  - [Blog, jekyll, Github, Python, 천재교육, 빅데이터, 데이터EDA, 데이터 EDA, 데이터분석, 데이터 분석, 이상치, 결측치, 모델링]

toc: true
toc_sticky: true

date: 2024-03-12
last_modified_at: 2024-03-12
---

{% include toc.html %}

### 3월 12일 강의 정리
[깃허브 링크1](https://github.com/gustjr7879/chunjae/blob/main/jae17.ipynb)      
[깃허브 링크2](https://github.com/gustjr7879/chunjae/blob/main/jae17.html)      

### 어제에 이어서
어제 class imbalanced 한 데이터 셋을 가지고 분석 및 모델링 하다가 집에 갔다.      
오늘은 이어서 진행했는데 집에서 여러가지 방법들을 생각해봤었다.     
또 데이터의 양이 약간 추가된 데이터를 주셔서 새롭게 전처리하고 모델링했으나 데이터 Target의 비율은 크게 변하지 않았다.       
따라서 그냥 생각해온걸 적용해보는 시간을 가졌다.       



#### 앙상블 
우선 언발랜스한 클래스 비율을 가진 데이터셋이 있을 때 이를 처리하는 방법들을 많이 찾아봤다.      
upsampling, downsampling의 경우 어느정도 잘 나눠져있는 데이터셋의 경우 잘 통하는 방법이지만 이 데이터의 경우 분포가 매우 안좋기 때문에 샘플링 방법이 오히려 독이된다.      
따라서 내가 생각한 방법은 앙상블을 사용하고 앙상블 모델 파라미터에 weight를 주면 단일 모델보다 잘 맞추지 않을까라는 생각을 했다.     
결과적으로는 재현율 값이 상승했지만 미미하게 상승했고 아쉬운 결과였다.    
여러가지 조합으로 해봤는데, 적은 class의 recall값이 높은 결과는 결론적으로 정확도도 매우 낮아서 사실상 underfitting된 것이다.       

#### 매트릭 러닝 (metric learning)
metric learning의 경우 클래스 기준으로 같으면 가깝게, 멀면 멀게 할 수 있지 않을까? 라는 생각이 있었다.    
따라서 기본적인 3-layer MLP모델을 만들고, TripletLoss를 사용해서 같은 클래스의 경우 가깝게 다른 클래스의 경우 멀게 만드는 작업을 했다.      
이를 위해서 dataset 또한 살짝 바꿔주는 과정을 거쳤다.      
이를 통해서 16차원으로 임베딩 시켰고, 학습률과 weight_decay는 살짝씩 조정하면서 결과를 지켜봤다.       
결과적으로는 MLP모델의 loss는 낮아지고 tsne로 시각화했더니 나름 봐줄만 했다 ! 유의미한 실험이였다     

따라서 이를 기반으로 데이터를 변형시키고, 다시 기본적인 모델들에 넣어서 분류를 해보았더니 안했을 때 보다 상승하는 것을 확인할 수 있었다.     

#### 다시 앙상블..
기본적인 랜덤포레스트 모델에서 오르는 것을 확인했기 때문에 바로 앙상블 모델에 사용했다.      
앙상블 모델에서 아쉽게 랜덤포레스트 모델보다 정확도는 오르지만 recall값은 오히려 떨어지는 경향을 보였고 따라서 SMOTE를 사용해서 오버샘플링을 한 후 다시 테스트 해봤다.     
매트릭러닝을 진행하고 오버샘플링을 하면 이전보다 더 잘되지 않을까? 라는 생각이였고, recall값이 11 -> 23%로 크게 상승했다.     
하지만 더 이상의 상승은 확인할 수 없었다. 그래도 생각보다 잘 먹혔고 metric learning을 좀 더 세밀하게 한다면 정말로 유의미한 결과를 볼 수 있다고 생각한다.     

#### 마지막 딥러닝
오버샘플링한 다음에 딥러닝을 적용시켜서 적절하게 학습한다면 정확도도 나름 유지되고 recall값도 잘나오지 않을까란 생각으로 빠르게 3-layer MLP를 만들어서 학습시켰다.     
파라미터는 조금씩 조정했고 class에 weights를 줘서 학습시켰다.      
결과적으로 전체 정확도가 72%에 recall값이 30%가 나오는 것을 확인했지만 막 엄청 맘에드는 결과는 아니다.     


#### 마치며
상당히 짧은 시간에 다양한 시도를 해봤지만 실패했고 모두 여기 작성하기에는 코드가 너무 많았기 때문에 패스하겠다. (코드 링크 참고해서 봐보세여)     
이 과정에서 다양한 생각을 오랜만에 해봤고 매트릭 러닝이 먹히는 것이 신기했다. 공부해볼만 한 것 같다.     
class unbalance에 대한 연구가 왜 많이 진행되고 있는지 알 것 같으며 예전 수업시간에 말했던 교수님의 말들이 생각났다. (언발란스하면 f1 score와 recall값들을 확인하라는)    
또한 데이터를 tensor로 변형하고 다시 df로 바꿨다가,, 하는 과정들을 통해서 데이터에 좀 더 익숙해진 것 같다.     
더해서 다양한 패키지와 함수들을 알아가서 좋았던 프로젝트(?)였다