---
layout: post
title:  "천재교육 빅데이터 7기 강의 정리 -4"
excerpt: "천재교육 4"

tags:
  - [Blog, jekyll, Github, Python]

toc: true
toc_sticky: true
 
date: 2024-02-01
last_modified_at: 2024-02-01
---

{% include toc.html %}

### 1월 31일 프로젝트

1월 31일엔 공공데이터를 받아와서 직접 분석해보는 실습을 진행했다.   
링크는 [깃허브](https://github.com/gustjr7879/chunjae)에 projects repos에 올려놨다.   
plotly로 시각화 해놨더니 ipynb로 저장 시 시각화 결과가 저장 안되어서 html파일도 올려놨다.

### 2월 1일 강의

이번 강의는 보고서 작성법부터 시작했다.   
총 2가지의 보고서 작성법을 배웠고, 이는 형식적이고 기술에 대한 이야기가 별로 없어서 ipynb파일로 정리하고 위의 깃허브 repo에 jae6.ipynb 파일로 업로드 해놨다.   

###### 데이터 전처리 (Data Preprocessing)
1. 데이터 : 정제되지 않은 사실
2. 정보 : 의미가 부여되어있고 조직화된 데이터   
즉 데이터를 정제하게되면 정보가 된다.(의미와 조직화 부여) 데이터는 분석에 쓸 수 없고 정보는 사용할 수 있다. 따라서 데이터를 전처리해서 정보로 바꿔주는 것이 중요하다.   
예전에는 데이터 수집이 큰 매리트가 있었지만 지금은 데이터가 많이 풀려있어서 개인이나 소규모 단위에서는 정제, 전처리가 중요하다.   
- 데이터 누락 : NaN (단, 누락된 자료가 엄청나게 적어서 무시해도 되거나, 누락된 데이터를 제외하고 사용해도 될 때는 처리 안하고 제외하는 편이다.)
- 데이터 오차 : 입력된 데이터가 범주를 크게 벗어난 것(나이 395세)
- 형태를 벗어난 값 : 올해 연도 '4월 2일'과 같이 데이터 형태에 맞지않은 값이 들어간 것이다.

##### 데이터 전처리 종류
1. 데이터 클리닝   
1) 중복 데이터 삭제(가장 먼저 작성된 것만 남기거나 가장 최신 기록만 남기거나..)
2) 구조적 문제 수정(주민번호 안에 생년월일, 성별이 들어가 있는데 또 입력하라고 한다)
3) 대소문자 일치(영어에서 주로 사용됨)
4) NA표기 통일(fillna = 일정값)
5) 이상치(outlier) 처리
6) 관련 없는 데이터 삭제(지역별 온도 데이터 활용하는데 예산이 들어가있다던지..)
7) 누락(NA)데이터 처리 (dropna)
8) 수정된 데이터 평가

2. 데이터 통합 (출처가 다양한 데이터를 단일화한다.)
1) 동일한 데이터를 통합(다양한 데이터셋에 같은 데이터가 포함되어 있다면 같은 데이터 기준으로 통합시킴)
2) 두 데이터 간의 차이를 확인한다.
3) 같은 의미를 가지는 데이터 검토
4) 같은 데이터를 포함한 정보 처리

3. 데이터 변환 (분석이 불가능하거나 어려운 형태를 분석 가능한 형태로 변환)
1) 단위 변환(화폐, kg등)
2) 문자열의 경우 파싱
3) 형태 변환
4) 여러 의미를 가진 데이터의 경우 분리저장

4. 데이터 축소 (데이터를 저차원, 저용량으로 축소)
1) 차원축소(PCA, t-SNE 등) : 원래 데이터의 큰 틀은 유지되지만 손실이 있다.
2) 유효숫자 변경
3) 수량 감소
4) 데이터 속성 제거
5) 클러스터링, 샘플링
6) 데이터 용량 축소

5. 데이터 이산화 (연속형 데이터를 범주형 데이터로 변경)
1) 기계학습을 위해서 많이 사용된다.
2) 차이가 큰 값에 가중치를 부여, 차이가 적은 값에 연관관계 부여를 예방한다.
3) 컴퓨터가 판단할 수 없다는 특성에 근거함

6. 결측치 이상치 처리 (분석 불가능하거나 크게 영향을 주는 데이터 처리)
1) 결측치 처리(zerofill, mean, median)
2) 이상치 처리(제거, 너무 많이 지워야한다면 대체) -> 대체는 보통 컷오프로 한다. (분포쪽으로 데이터를 들고온다. 내용이 왜곡되는 현상을 줄이지만 너무 많은 데이터가 옮겨진다면 데이터의 신뢰도가 하락한다.)
3) 기계학습을 이용한 대체

7. 표준화(Standard-), 정규화(Normal-) : 데이터의 분포에 따른 특성 제거 또는 통계를 위한 변환
1) 표준화 : 정규분포의 속성을 가지도록 데이터 분포가 변화된다. 데이터 범위의 제한이 없다. Z-score
2) 정규화 : 데이터 분포는 유지된다. 데이터 범위의 제한이 생긴다. min-max scaling   
여기까지 데이터 전처리에 대한 대략적인 부분을 살펴보았다. 처음부터 다 외우려고 하지말고 뭐가 있는지 얼추 알아놓고 나중에 생각날때마다 보면서 이런거였구나 하는식으로 공부하면 될 것 같다.
    

##### 실제 데이터 만질때 자주 사용하는 함수들 실습
Dataframe을 출력할 때 
```python
print(media.head(5))
```
와 같이 일부분만 출력해서 너무 많은 공간을 차지하는걸 방지할 수 있다.   
```python
print(media['센터명'].unique())
```
**unique()**함수를 사용해서 어떤 데이터가 있는지 확인할 수 있다.   
결측치 (NaN)값이 있다면 dropna를 통해서 제거할 수 있다.
```python
media = media.dropna(how='all',axis = 0)
```
**how = 'all'**는 모든 값이 NaN이라면 이고 **axis=0**는 행 데이터를 의미한다. 즉, 모든 값이 NaN이면 행으로 제거하라는 말이 된다.   
중복되는 값을 슬라이싱으로 제거해보자.
```python
media['센터명'] = media['센터명'].apply(lambda x: x[:2])
```
와 같이 센터명 앞 두글자만 남기고 다 지워버릴 수 있다. **apply**와 **lambda**는 함께 자주 사용되니까 사용법도 익혀두자   
이번에는 교육대상구분을 미취학, 일반시민, 중등 으로 구분하도록 하자
```python
dict1 = {'유아':'미취학','5~7세':'미취학','일반시민':'일반시민','초등생 이상':'일반시민','중등':'중등'}
media['교육대상구분'] = [dict1[i] for i in media['교육대상구분']]
```
으로 dictionary로 묶어주고 이를 변경할 수 있다.   
함수를 사용해서 변경하는 방법도 있다.
```python
def change(x):
    if x == '월,화,수,목,금,토':
        return '주중'
    return x
media['운영요일'] = media['운영요일'].apply(lambda x : change(x))
```
으로 운영요일이 계속 이어지는 데이터만 주중으로 변경해줄 수 있다.   
또한 이 데이터에서는 교육oo일자가 str데이터 형식으로 되어있는데 이를 **datetime**패키지를 이용해서 날짜 형식으로 변환할 수 있다.
```python
media['교육시작일자'] = media['교육시작일자'].apply(lambda x : datetime.strptime(x,'%Y-%m-%d'))
```
이렇게하면 날짜별 연산이 가능해진다.   
마지막으로는 강좌내용이 너무 난잡하니까 비슷한것끼리 묶어주는 실습을 했다.
```python
media['강좌내용'] = media['강좌내용'].apply(lambda x : '크로마키' if '크로마키' in x else x)
media['강좌내용'] = media['강좌내용'].apply(lambda x : '더빙' if '더빙' in x else x)
for i in ['뉴스','라디오','라이브커머스']  :
    media['강좌내용'] = media['강좌내용'].apply(lambda x : '컨텐츠' if i in x else x)
media['강좌내용'] = media['강좌내용'].apply(lambda x : '인공지능' if '인공지능' in x else x)
```
위와 같이 특정 문자열이 전체 문자열에 들어가 있으면 변경해주는 작업도 가능하고, 여러개 바꾸기 위해서 **for**문을 사용해서 돌리는 방법도 사용해보았다.   

##### 마무리
보고서 작성방법은 여기 안나와있지만 대략적으로 어떻게 작성해야하는지, 어떤식으로 발표 자료를 준비해야하는지 알 수 있었고, 어떤 업무가 들어왔을 때 개발자나 분석가가 해야할 흐름도 알게 되었다.   
또한 데이터 전처리의 중요성과 종류 세부적인 방법들도 어렴풋이 배웠고 강사님이 직접 그림을 그려서 설명해준 컷오프와 같은 내용은 알지 못했던 내용인데 이해가 잘 되었다.   
마지막으로 자주 사용되는 함수를 정리하고 직접 실습하면서 데이터 처리를 좀 더 잘하게 된 것 같다.