---
layout: post
title:  "천재교육 빅데이터 7기 강의 정리 -11"
excerpt: "천재교육 11"

tags:
  - [Blog, jekyll, Github, Python, 천재교육, 빅데이터, 데이터EDA, 데이터 EDA, 데이터분석, 데이터 분석, 이상치, 결측치, 모델링]

toc: true
toc_sticky: true

date: 2024-03-11
last_modified_at: 2024-03-11
---

{% include toc.html %}

### 3월 11일 강의 정리
[깃허브 링크1](https://github.com/gustjr7879/chunjae/blob/main/jae16.ipynb)      
[깃허브 링크2](https://github.com/gustjr7879/chunjae/blob/main/jae16 copy.ipynb)      

### 데이터 분석부터 모델링까지
오늘은 재미있게 데이터 분석부터 모델링까지 해봤다.     
데이터 분석이야 EDA를 통해서 대충 비율이 어떻게 되고 어떤 feature를 사용할 것인지에 대해서 알아보고, feature들의 분포와 target과의 연관성 위주로 확인했다.      
그리고 동시에 모델링을 하기 위한 방법들을 배웠는데, scale을 할 때 주의사항과 sampling에 대한 내용이 기억에 남는다.     
또한 결측치, 이상치에 대해서 자세하게 알게 되었다.     


#### 결측치
결측치는 보통 NaN값이라고들 한다. 나도 입버릇처럼 말한다.     
데이터를 분석할 때 가장 먼저 확인하는 것이기도 하고 NaN값이 많을때, 적을때 그리고 데이터 특성에 따라서로 구분한다.      
갯수가 적으면 보통 mean값, 가장 많이 등장한 값 등으로 대체한다. (다만 데이터가 어떤지 먼저 확인해야한다. 학년에 대한 데이터인데 평균값으로 넣으면....)     
또한 데이터들의 분포를 보면서 채워넣는 방법 또한 있다. (k-NN 알고리즘이나 딥러닝, XGBoost 등)     
하지만 결측치가 적고 데이터의 전체 양이 많은 경우에는 평범한 방법을 사용하도록 하자. 시간이 오래 걸린다.      
또한 drop하는 경우도 있다. 결측치가 너무나도 많다면 분석하는 사람이 봤을 때 목표와 다르다고 생각되면 drop하는 것이 좋은 방법이 될 수 있다.      

#### 이상치
이상치는 말 그대로 이상한 값이라고 생각하면 된다.      
일반적인 데이터들의 분포와 맞지 않게 너무나도 특이한 값을 가지고 있는 경우 해당된다.      
예를들어서 직장인 연봉을 파악하고 있는데 뜬금없이 이재용 연봉이 들어간다면 ..? 그 데이터들은 이상해질 것이고 예측 또한 쉽지 않아진다.      
따라서 이런 이상치 값들을 제거 및 처리해주어야 한다.     
처리하는 방법은 결측치와 비슷하다. 제거하는 방법이 있고, Z-score를 사용해서 찾고 제거하거나, IQR(사분위수)로 판단하거나, Isolation Forest 등 다양한 방법들이 존재한다.       
보통 상한값, 하한값 으로 대체할 수 있다.       

#### 스케일링(Normalization)
데이터 분석과 전처리를 종료해서 이제 모델에 학습을 시키려고 한다고 해보면, 어떤 column은 최대값이 1000 최소값이 -500이고, 어떤 column은 최대값이 1, 최소값이 0.3 이라고 하면 이 데이터를 그대로 학습시키면 좋은 결과를 얻을 수 없다.     
이는 당연하게 정규화, 스케일링을 진행해줘야하는데, 이 순서를 정확히 알고 있어야한다.      
우선 모델을 학습시키기 위한 데이터에는 train data와 test data가 존재한다.       
이때 스케일러는 train data를 가지고 학습하고 test data에는 그냥 적용하는 것이다.      
데이터 유출의 우려가 있어서 그런 것 같다.      


#### Sampling
오늘 Target의 비율의 차이가 매우매우 큰 ,, 데이터를 가지고 모델을 만들어봤다.       
이렇게 비율의 차이가 있다면 한쪽 label로의 학습이 너무 많이 진행되어서 모델이 제대로 예측하지 못한다.      
따라서 이런 경우에는 sampling을 해줘야한다.      
샘플링에는 upsampling & downsampling이 존재하고 나는 알고 있었다. (GNN의 악몽...)      
머신러닝기법을 사용해서 업샘플링을 진행하는데, 존재하는 적은 수의 라벨을 뻥튀기 시켜서 학습 데이터를 만드는 것이다.      
이 방법 또한 무 조 건 학습데이터에 적용해야한다. 테스트 데이터에 적용하면 바로 유출이다.      
대표적으로 imblearn의 SMOTE가 있고 다양하게 파생되어 있다. 이는 다른 블로그를 찾아보는 것이 더 좋을 것이다.     
downsampling은 말 그대로 적은 쪽에 맞춰주는 것이다.      
내가 예전에 정보보안 수업을 들을 때 다운샘플링을 해서 모델을 학습시켰던 경험이 존재한다.      
하지만 이 방법은 데이터 소실의 우려가 존재하고 데이터의 양이 매우 적었던 오늘의 경우는 적용시킬 수 없는 방법이다.      
그래서 upsampling을 진행했는데 이것도 비율이 너무 안맞고 데이터의 양이 너무너무 적어서 제대로 작동되지 않는다.      
깃허브 링크 1에 들어가면 여러가지 방법을 사용해서 에측을 잘 하게 만드려는 노력들이 있다.      
깃허브 링크 2에 들어가면 데이터 유출의 위험성을 보여준다.       
테스트 데이터는 무조건 건들지 말고, 어떤 기법을 사용할 때 항상 생각해보면서 사용하도록 하자.


#### 마치며
오늘은 너무 피곤해서 코드도 대충 짜고 모델링도 대충 했는데, 극악의 target 비율을 어떻게 하면 해결할 수 있을까 찾아보면서 오히려 더 오래 많이 했던 것 같다.      
그래도 결측치, 이상치를 처리하는 방법과 비율을 맞춰주는 다양한 방법들을 알게 된 것 같다.       
앞으로 면접에서 이런 질문이 들어오면 아는척하면서 말할 수 있을 것 같다 ㅎㅎ.