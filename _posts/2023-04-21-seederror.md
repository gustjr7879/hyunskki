---
layout: post
title:  "seed 고정 오류"
excerpt: "모델 재현 시 seed고정 오류에 대해서"

tags:
  - [Blog, jekyll, Github, Python]

toc: true
toc_sticky: true
 
date: 2023-03-09
last_modified_at: 2023-03-09
---
{% include toc.html %}

### 1. 계기
연구를 진행 중에 모델 성능이 재현되지 않는 문제가 발생했다.
이 문제는 코드를 돌릴때마다 다른 결과값이 나왔다
GCNII와 FSGNN이라는 모델에서 그런 현상이 발견되었는데
FSGNN의 base 모델은 GCNII이므로 사실상 GCNII에서 시작된 오류인 것을
알 수 있었다.
https://github.com/chennnM/GCNII
에 들어가면 코드를 확인할 수 있다.

### 2. 문제
문제가 되는건 seed가 고정되었음에도 돌릴때마다 test 정확도의 10epoch 평균값이
나오게 되는데, 이 10번 평균값이 계속 변한다는 것이다.
정확히 말하면 2epoch 부터 다르게 나타난다.(1epoch까지는 동일함)
이를 해결하기 위해서 연구실 사람들하고 모여서 계속 봤지만 이유를 정확하게 밝혀내지
못했다.

### 3. 의심 후보
의심가는 후보로는 다른 library에서 random 이나 seed를 변경할만한 부분이
있다는 점이였다. 그래서 다른 라이브러리를 다 뜯어보기 시작했다.

이는 시간낭비였다 

또 다른 여러가지 가설들이 있었지만, 다 실패로 돌아갔다.
### 4. 해결
상당히 많은 시간을 잡아먹은 것 치고 좀 간단하게 해결되었다.
문제는 cuda의 부동소수점 오차(오류)가 발생한 것이다.

해당 코드를 cpu에서 진행하니 문제가 해결되었다.
이 두가지 모델 다 train epoch값이 상당히 많은 특징이 있는데, 부동소수점 오류가
계속 누적이 되면서 loss에 영향을 끼치게 되었고 이는 early stop 지점을 변경하였다
또 seed 호출횟수가 변경되니까 전체 결과값이 계속 달랐다.

그래서 cpu로 옮겨서 비교해보았다
{% highlight css %}
python3 train.py > output1.txt; python3 train.py > output2.txt; cmp output1.txt output2.txt
{% endhighlight %}
로 비교를 하니 다른점은 걸린 총 시간만 다르게 나왔다.


### 4-1. 해결-2
torch.spmm에서 시드가 고정안된다는 이슈가 있었다.
cuda version 10.2에서는 정상적으로 작동하고 11.6이상 버전에서는 고정이 안된다 (dlpc 환경세팅으로 확인함)
https://github.com/pytorch/pytorch/pull/75784 에서 나온 확인할 수 있는 이슈이다.
cuda의 cusparse spmm에서 연산괴정에서 고정이 되지않는다.
해당 문제를 torch에서 확인은 하였고 pull-request까지 나왔지만 merge후 릴리즈버전으로 고쳐지지 않음.

torch_sparse라이브러리의 spmm으로 대체하는 방법으로 해결하였다. 또한 환경변수 세팅이 필요하였음.
{% highlight css %}
os.environ["CUBLAS_WORKSPACE_CONFIG"]=":4096:8"
또한 이전에 내가 하던 실험에서 dgl라이브러리도 gpu로 돌리면 시드가 고정되지 않는 문제가 있었다. 따라서 dgl을 torch_geometric으로 대체해서 사용하는 것으로 해결하였다.


{% endhighlight %}

### 5. 문제 해결 이후
문제를 해결했으니 부동소수점, 고정소수점에 대해서 다시 한번 보고 넘어가자는
의미로 정리를 해보려고 한다.

컴퓨터는 2진수로 모든것을 표현한다. 정수뿐만 아니라 실수도 2진수로 표현하는데,
정수는 나름 표현하기 간단하지만, 실수는 복잡하다.
실수를 표현하기 위해서 고정소수점 이라는 개념과 부동소수점 이라는 개념이 생겼다.

#### 고정소수점
fixed point는 실수는 보통 정수부와 소수부로 나뉘는데, 소수부의 자릿수를 
고정해서 고정된 자리수의 실수를 표현하는 방식이다.
총 32비트에 들어가며(1비트=부호, 15비트=정수부, 16비트=소수부)
정수부와 소수부의 자리수가 크지않기때문에 표현할 수 있는 범위가 상당히
작다는 단점이 있다. 또한 정밀도가 떨어지게 된다는 단점도 따라오게 된다.

#### 부동소수점
floating point 방식은 실수를 가수부와 지수부로 표현하는 방식이다.
즉 a*2^b 형식으로 저장하는데 a는 1<=a<2 이다.
±(1.가수부)×2^지수부-127 이런 수식을 사용하여서 표현할 수 있는 수의
범위를 상당히 많이 증가시켰다. 64비트로 표현 가능하다
(1비트=부호, 11비트=지수부, 52비트=가수부)
하지만 부동소수점은 범위를 넓히는 대신에 항상 오차가 발생한다는 단점이 있다.
즉 10진수를 정확하게 표현할 수 없다. (순환소수의 경우 자릿수를 넘어가게 되면
필연적으로 오차가 발생함)

### 6. 마무리
시간을 오래 잡아먹은 오류 치고 좀 간단하게 처리해서 허무하면서도 개운하다.
시간은 좀 오래걸리겠지만, 정확도 재현이 되는 seed를 찾아내고 그보다 성능이
향상된 내 결과를 올릴 수 있을 것이라는 생각에 좀 행복하기도하다.

### 7. 참고
https://velog.io/@syleemk/CS-%EB%B6%80%EB%8F%99-%EC%86%8C%EC%88%98%EC%A0%90-%EC%98%A4%EC%B0%A8
여기 블로그 맨 밑에 보면 부동소수점 2진수 표현방식 등 cs정보를 쌓기 좋아보인다.
