---
layout: post
title:  "ERROR 정리"
excerpt: "cuda, huggingface"


tags:
  - [Blog, jekyll, Github, Python, Error]

toc: true
toc_sticky: true
 
date: 2024-03-30
last_modified_at: 2024-03-30
---
{% include toc.html %}

### Huggingface error
오랜만에 허깅페이스를 해보면서 많이 까먹었다는 사실을 알게 되었다.    
연구를 진행하면서 허깅페이스를 사용하는 것 보다 내가 그냥 짜서 돌리고 하는 방식으로 많이 진행했기 때문,,,    
근데 요즘 활발하기도 하고 많은 모델을 쉽게 사용할 수 있다는 아주아주 큰 매리트가 있기 때문에 시간날때마다 정리를 해서 완전히 나의 것으로 만들것이다.     

google bert 모델을 가지고 와서 fine tuning하는 과정에서 발생한 오류를 정리한다.     

#### ValueError: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,token_type_ids,attention_mask.
모델에 데이터를 Trainer로 집어넣는 과정에서 발생한 오류이다.    
이 오류는 뭐가 없어서 return해주지 못한다는 것이다.    
hugging face에 있는 pretrained model들은 데이터의 이름이 어느정도 다 정해져있다.    
라벨을 예시로 들면 어떤 모델은 target, 다른 모델은 labels 이런식으로 말이다.     
하지만 데이터가 외부 데이터라면 이름이 다를 수 있다.     
나같은 경우 yelp-review 데이터를 사용했는데 이 데이터에서 labels는 stars이다.    
따라서 labels를 찾지 못해서 발생한 오류로     

```python

dataset.rename_colum(old, new)

```      

로 간단하게 이름을 변경해줘서 간단하게 수정 가능했다.     

  
#### RuntimeError: CUDA error: device-side assert triggered
이 에러는 참 나를 괴롭게한다.    
딥러닝을 하다보면 자주 등장하는 에러로 처음엔 뭔가 싶어서 검색도 해보고 하라는 방법을 사용해도 안되었다.    
생각해보면 예전에도 안되었던 것 같다.     
근데 희안하게 주피터에서 하다보면 다른 부분에서 갑자기 이 에러가 발생하는 것을 확인했고, 코드나 데이터의 문제가 아닌 무언가가 있다는 것으로 판단했다.    
그래서 코드를 한줄한줄 분리한 다음에 memory cpu gpu 사용량을 확인해가본 결과, fine tuning을 하기 위해서 모델을 잠시나마 학습을 시켜야하는데 모델의 크기가 너무 크다 보니까 gpu 메모리를 다 먹어버린 결과였다.     
뭐... 모델의 사이즈가 크기 때문에 잘 맞추는거라고 생각하지만 요즘 모델들은 커도 너무 크다.     
cpu로 완전히 넘기고 처리해보거나 좀 가벼운 모델을 가지고 파인튜닝할 예정이다.     

참고로 어제 진행한 stable diffusion 모델 또한 cpu에서 겨우겨우 돌리면서 실험하고 있다. ㅎ      
나중에 돈이 생기면 꼭 컴퓨터 업그레이드 할거다.